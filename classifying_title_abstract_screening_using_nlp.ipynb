{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bca7405-22dc-43a1-b3c4-5aaf7b4059b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import bibtexparser\n",
    "from bibtexparser.bparser import BibTexParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb62d2e0-47e7-49a0-96aa-347aee8f387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = \"./SavedModels/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0377ef2-d7ce-4453-a4dd-0f7448f05fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b4f60b-b90e-4e21-9d69-246845c072f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = pd.read_csv(\"./data/title_abstract_eval_dataset.csv\")\n",
    "test_encodings = tokenizer(eval_dataset['Title_and_Abstract'].astype(str).tolist(), truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a9b35f7-1dd8-48cf-957f-5ee80b5646fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecdb6f97-794e-4dae-8e0f-1e36d9349086",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d24c2454-5d73-48aa-b3af-d2047c13a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for train, validation, and test\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a20eb1e2-d209-4ba1-b955-1af2000014b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# Choose device available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a4fd769-cfa0-483f-b908-dba590317d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_papers(model, dataloader, device, tokenizer):\n",
    "    \"\"\"Classify papers using the trained model and return a DataFrame with texts and their classifications.\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    texts = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            batch_texts = [tokenizer.decode(t, skip_special_tokens=True) for t in batch['input_ids']]\n",
    "            texts.extend(batch_texts)\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            predicted_labels = torch.argmax(logits, dim=1)\n",
    "            predictions.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "    # Create DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'Title_and_Abstract': texts,\n",
    "        'Accepted_for_Full_Text': predictions\n",
    "    })\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b9017-f27d-4452-8bcd-706d1bc91566",
   "metadata": {},
   "source": [
    "## Set Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc211a54-0812-4c3b-9a94-59bd2f80a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    \"\"\"Set all random seeds to a fixed value and possibly disable nondeterministic algorithms.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a15dd61-24d0-40de-80e8-a83531dc7923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed()\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2,  # Ensure this matches the setup during training\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "# Step 2: Load the saved model weights\n",
    "model_path = saved_model_dir+'DistilBertForSequenceClassification_best_model.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70cf1e25-848e-4c50-88f8-26886c54c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = classify_papers(model, test_dataloader, device, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa6c94d8-82ab-4efc-963e-deec732431b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title_and_Abstract</th>\n",
       "      <th>Accepted_for_Full_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10493</th>\n",
       "      <td>fog based integrated nutrient management syste...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10494</th>\n",
       "      <td>an automated irrigation system for agriculture...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10495</th>\n",
       "      <td>using a compositional function hybridization o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>a study on secure network slicing in 5g</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10497</th>\n",
       "      <td>advancing cattle welfare : ultra low - power h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>wireless sensor network based greenhouse monit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10499</th>\n",
       "      <td>agrostring 2. 0 : a distributed - ledger based...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10500</th>\n",
       "      <td>performance of routing protocol for low - powe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10501</th>\n",
       "      <td>churn - tolerant leader election protocols</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10502</th>\n",
       "      <td>holistic technologies for managing internet of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title_and_Abstract  \\\n",
       "10493  fog based integrated nutrient management syste...   \n",
       "10494  an automated irrigation system for agriculture...   \n",
       "10495  using a compositional function hybridization o...   \n",
       "10496            a study on secure network slicing in 5g   \n",
       "10497  advancing cattle welfare : ultra low - power h...   \n",
       "10498  wireless sensor network based greenhouse monit...   \n",
       "10499  agrostring 2. 0 : a distributed - ledger based...   \n",
       "10500  performance of routing protocol for low - powe...   \n",
       "10501         churn - tolerant leader election protocols   \n",
       "10502  holistic technologies for managing internet of...   \n",
       "\n",
       "       Accepted_for_Full_Text  \n",
       "10493                       0  \n",
       "10494                       1  \n",
       "10495                       1  \n",
       "10496                       0  \n",
       "10497                       1  \n",
       "10498                       0  \n",
       "10499                       0  \n",
       "10500                       0  \n",
       "10501                       0  \n",
       "10502                       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16e5dcff-1ef0-40aa-a2d7-68cd7dcce67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_df = results_df[results_df['Accepted_for_Full_Text'] == 1]\n",
    "not_relevant_df = results_df[results_df['Accepted_for_Full_Text'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9e72c5d-8c73-467c-a98f-430ce251f703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2967, 2), (7536, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_df.shape, not_relevant_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "195c90b2-d084-4d5d-8878-f9bd9ba1e9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title_and_Abstract</th>\n",
       "      <th>Accepted_for_Full_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>novel method for crop growth tracking with dee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>aiot in agriculture : safeguarding crops from ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>artificial intelligence in the development of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>machine learning ( ml ) algorithms on iot and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>conceptualizing a holistic smart dairy farming...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10491</th>\n",
       "      <td>iot based precision agri - bot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10492</th>\n",
       "      <td>a fog - based smart agriculture system to dete...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10494</th>\n",
       "      <td>an automated irrigation system for agriculture...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10495</th>\n",
       "      <td>using a compositional function hybridization o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10497</th>\n",
       "      <td>advancing cattle welfare : ultra low - power h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2967 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title_and_Abstract  \\\n",
       "12     novel method for crop growth tracking with dee...   \n",
       "21     aiot in agriculture : safeguarding crops from ...   \n",
       "23     artificial intelligence in the development of ...   \n",
       "29     machine learning ( ml ) algorithms on iot and ...   \n",
       "30     conceptualizing a holistic smart dairy farming...   \n",
       "...                                                  ...   \n",
       "10491                     iot based precision agri - bot   \n",
       "10492  a fog - based smart agriculture system to dete...   \n",
       "10494  an automated irrigation system for agriculture...   \n",
       "10495  using a compositional function hybridization o...   \n",
       "10497  advancing cattle welfare : ultra low - power h...   \n",
       "\n",
       "       Accepted_for_Full_Text  \n",
       "12                          1  \n",
       "21                          1  \n",
       "23                          1  \n",
       "29                          1  \n",
       "30                          1  \n",
       "...                       ...  \n",
       "10491                       1  \n",
       "10492                       1  \n",
       "10494                       1  \n",
       "10495                       1  \n",
       "10497                       1  \n",
       "\n",
       "[2967 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7700d72-cc2b-45a4-ac5a-2e848dbb288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_bib_file_to_dict(file_path):\n",
    "    \"\"\"Parse a BibTeX file and return a list of dictionaries with combined title and abstract and full entry data.\"\"\"\n",
    "    with open(file_path, encoding='utf-8') as bibtex_file:\n",
    "        parser = BibTexParser(common_strings=True)\n",
    "        bib_database = bibtexparser.load(bibtex_file, parser=parser)\n",
    "\n",
    "    entries_list = []\n",
    "    for entry in bib_database.entries:\n",
    "        title = entry.get('title', '').replace('{', '').replace('}', '').replace('\\n', ' ').strip()\n",
    "        abstract = entry.get('abstract', '').replace('{', '').replace('}', '').replace('\\n', ' ').strip()\n",
    "        text_feature = f\"{title} {abstract}\".strip()\n",
    "        entry_dict = {\n",
    "            'combined_text': text_feature,\n",
    "            'full_entry': entry  # Store the whole entry for later use\n",
    "        }\n",
    "        entries_list.append(entry_dict)\n",
    "\n",
    "    return entries_list\n",
    "\n",
    "def normalize_and_process_text(texts, tokenizer):\n",
    "    \"\"\"Process texts using a tokenizer and decode them back to strings.\"\"\"\n",
    "    tokenized_texts = tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "    decoded_texts = [tokenizer.decode(t, skip_special_tokens=True) for t in tokenized_texts.input_ids]\n",
    "    return decoded_texts\n",
    "\n",
    "def find_matches(predicted_texts, processed_extracted_texts, full_entries):\n",
    "    matched_entries = []\n",
    "    unmatched_texts = []\n",
    "\n",
    "    for pred_text in predicted_texts:\n",
    "        if pred_text in processed_extracted_texts:\n",
    "            index = processed_extracted_texts.index(pred_text)\n",
    "            matched_entries.append(full_entries[index]['full_entry'])\n",
    "        else:\n",
    "            unmatched_texts.append(pred_text)\n",
    "\n",
    "    return matched_entries, unmatched_texts\n",
    "\n",
    "\n",
    "def entry_to_bibtex(entry):\n",
    "    \"\"\"Convert a dictionary entry to a BibTeX-formatted string.\"\"\"\n",
    "    bibtex_entry = f\"@{entry['ENTRYTYPE']}{{{entry['ID']},\\n\"\n",
    "    for key, value in entry.items():\n",
    "        if key not in ['ENTRYTYPE', 'ID']:  # Skip type and ID as they are already used\n",
    "            bibtex_entry += f\"  {key} = {{{value}}},\\n\"\n",
    "    bibtex_entry += \"}\\n\"\n",
    "    return bibtex_entry\n",
    "\n",
    "\n",
    "def save_matched_entries_to_bib(matched_entries, filename):\n",
    "    \"\"\"Save matched entries to a BibTeX file.\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        for entry in matched_entries:\n",
    "            bibtex_string = entry_to_bibtex(entry)\n",
    "            file.write(bibtex_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d695fce3-0e59-4f6f-9bd9-8d59f25a0940",
   "metadata": {},
   "source": [
    "## Getting the Relevant Papers After the Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8e1fc9e-a2ae-4d2a-9e92-cecbcfb208b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_bib_file_dir = \"data/Papers_after_duplicates.bib\"\n",
    "extracted_texts = [entry['combined_text'] for entry in parse_bib_file_to_dict(original_bib_file_dir)]\n",
    "processed_extracted_texts = normalize_and_process_text(extracted_texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64b6c28e-47ee-4a77-9f45-9e8fb6b39ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_predicted_titles_and_abstracts = relevant_df['Title_and_Abstract'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5e5c8a-8063-41bc-a73a-d7fe80c86adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_entries = parse_bib_file_to_dict(original_bib_file_dir)\n",
    "processed_full_texts = normalize_and_process_text([entry['combined_text'] for entry in full_entries], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe90cdd-7d9b-4912-bd3a-f2b2678462b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_matched_full_entries, rl_unmatched_predicted_texts = find_matches(rl_predicted_titles_and_abstracts, processed_full_texts, full_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fcb8d7-0005-4ac9-84e5-6983d9b551b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_matched_full_entries[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be614d42-b5b1-4363-9681-f12344c7c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_matched_entries_to_bib(rl_matched_full_entries, 'relevant_papers_title_and_abstract_screened.bib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba1899a-435d-478a-ac5e-3d9f6e66dd34",
   "metadata": {},
   "source": [
    "## Getting the Irrelevant Papers After the Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa68e0f-d1f4-44dd-8b0c-9acf5c24701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrl_predicted_titles_and_abstracts = non_relevant_df['Title_and_Abstract'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ba4700-6bd9-4f27-9345-21f442fec0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrl_matched_full_entries, nrl_unmatched_predicted_texts = find_matches(nrl_predicted_titles_and_abstracts, processed_full_texts, full_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19fbb46-9c69-4fb7-ac60-7c39f3e4417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_matched_entries_to_bib(rl_matched_full_entries, 'relevant_papers_title_and_abstract_screened.bib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
