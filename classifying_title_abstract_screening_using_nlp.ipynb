{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bca7405-22dc-43a1-b3c4-5aaf7b4059b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import bibtexparser\n",
    "from bibtexparser.bparser import BibTexParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb62d2e0-47e7-49a0-96aa-347aee8f387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = \"./SavedModels/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0377ef2-d7ce-4453-a4dd-0f7448f05fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b4f60b-b90e-4e21-9d69-246845c072f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = pd.read_csv(\"./data/title_abstract_eval_dataset.csv\")\n",
    "test_encodings = tokenizer(eval_dataset['Title_and_Abstract'].astype(str).tolist(), truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a9b35f7-1dd8-48cf-957f-5ee80b5646fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecdb6f97-794e-4dae-8e0f-1e36d9349086",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d24c2454-5d73-48aa-b3af-d2047c13a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders for train, validation, and test\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a20eb1e2-d209-4ba1-b955-1af2000014b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# Choose device available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a4fd769-cfa0-483f-b908-dba590317d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_papers(model, dataloader, device, tokenizer):\n",
    "    \"\"\"Classify papers using the trained model and return a DataFrame with texts and their classifications.\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    texts = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            batch_texts = [tokenizer.decode(t, skip_special_tokens=True) for t in batch['input_ids']]\n",
    "            texts.extend(batch_texts)\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            predicted_labels = torch.argmax(logits, dim=1)\n",
    "            predictions.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "    # Create DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'Title_and_Abstract': texts,\n",
    "        'Accepted_for_Full_Text': predictions\n",
    "    })\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b9017-f27d-4452-8bcd-706d1bc91566",
   "metadata": {},
   "source": [
    "## Set Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc211a54-0812-4c3b-9a94-59bd2f80a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    \"\"\"Set all random seeds to a fixed value and possibly disable nondeterministic algorithms.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a15dd61-24d0-40de-80e8-a83531dc7923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed()\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2,  # Ensure this matches the setup during training\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "# Step 2: Load the saved model weights\n",
    "model_path = saved_model_dir+'DistilBertForSequenceClassification_best_model.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70cf1e25-848e-4c50-88f8-26886c54c842",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = classify_papers(model, test_dataloader, device, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa6c94d8-82ab-4efc-963e-deec732431b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title_and_Abstract</th>\n",
       "      <th>Accepted_for_Full_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10493</th>\n",
       "      <td>fog based integrated nutrient management syste...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10494</th>\n",
       "      <td>an automated irrigation system for agriculture...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10495</th>\n",
       "      <td>using a compositional function hybridization o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10496</th>\n",
       "      <td>a study on secure network slicing in 5g</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10497</th>\n",
       "      <td>advancing cattle welfare : ultra low - power h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10498</th>\n",
       "      <td>wireless sensor network based greenhouse monit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10499</th>\n",
       "      <td>agrostring 2. 0 : a distributed - ledger based...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10500</th>\n",
       "      <td>performance of routing protocol for low - powe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10501</th>\n",
       "      <td>churn - tolerant leader election protocols</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10502</th>\n",
       "      <td>holistic technologies for managing internet of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title_and_Abstract  \\\n",
       "10493  fog based integrated nutrient management syste...   \n",
       "10494  an automated irrigation system for agriculture...   \n",
       "10495  using a compositional function hybridization o...   \n",
       "10496            a study on secure network slicing in 5g   \n",
       "10497  advancing cattle welfare : ultra low - power h...   \n",
       "10498  wireless sensor network based greenhouse monit...   \n",
       "10499  agrostring 2. 0 : a distributed - ledger based...   \n",
       "10500  performance of routing protocol for low - powe...   \n",
       "10501         churn - tolerant leader election protocols   \n",
       "10502  holistic technologies for managing internet of...   \n",
       "\n",
       "       Accepted_for_Full_Text  \n",
       "10493                       0  \n",
       "10494                       1  \n",
       "10495                       0  \n",
       "10496                       0  \n",
       "10497                       1  \n",
       "10498                       0  \n",
       "10499                       0  \n",
       "10500                       0  \n",
       "10501                       0  \n",
       "10502                       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16e5dcff-1ef0-40aa-a2d7-68cd7dcce67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_df = results_df[results_df['Accepted_for_Full_Text'] == 1]\n",
    "not_relevant_df = results_df[results_df['Accepted_for_Full_Text'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9e72c5d-8c73-467c-a98f-430ce251f703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2261, 2), (8242, 2))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_df.shape, not_relevant_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "195c90b2-d084-4d5d-8878-f9bd9ba1e9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title_and_Abstract</th>\n",
       "      <th>Accepted_for_Full_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>novel method for crop growth tracking with dee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>aiot in agriculture : safeguarding crops from ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>conceptualizing a holistic smart dairy farming...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>plant disease detection : electronic system de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>improving deep learning classifiers performanc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10484</th>\n",
       "      <td>temperature and humidity control algorithm for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10491</th>\n",
       "      <td>iot based precision agri - bot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10492</th>\n",
       "      <td>a fog - based smart agriculture system to dete...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10494</th>\n",
       "      <td>an automated irrigation system for agriculture...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10497</th>\n",
       "      <td>advancing cattle welfare : ultra low - power h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2261 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title_and_Abstract  \\\n",
       "12     novel method for crop growth tracking with dee...   \n",
       "21     aiot in agriculture : safeguarding crops from ...   \n",
       "30     conceptualizing a holistic smart dairy farming...   \n",
       "41     plant disease detection : electronic system de...   \n",
       "42     improving deep learning classifiers performanc...   \n",
       "...                                                  ...   \n",
       "10484  temperature and humidity control algorithm for...   \n",
       "10491                     iot based precision agri - bot   \n",
       "10492  a fog - based smart agriculture system to dete...   \n",
       "10494  an automated irrigation system for agriculture...   \n",
       "10497  advancing cattle welfare : ultra low - power h...   \n",
       "\n",
       "       Accepted_for_Full_Text  \n",
       "12                          1  \n",
       "21                          1  \n",
       "30                          1  \n",
       "41                          1  \n",
       "42                          1  \n",
       "...                       ...  \n",
       "10484                       1  \n",
       "10491                       1  \n",
       "10492                       1  \n",
       "10494                       1  \n",
       "10497                       1  \n",
       "\n",
       "[2261 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7700d72-cc2b-45a4-ac5a-2e848dbb288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_bib_file_to_dict(file_path):\n",
    "#     \"\"\"Parse a BibTeX file and return a list of raw combined title and abstract entries.\"\"\"\n",
    "#     with open(file_path, encoding='utf-8') as bibtex_file:\n",
    "#         parser = BibTexParser(common_strings=True)\n",
    "#         bib_database = bibtexparser.load(bibtex_file, parser=parser)\n",
    "\n",
    "#     entries_list = []\n",
    "\n",
    "#     for entry in bib_database.entries:\n",
    "#         # Extract title and abstract, handle missing fields\n",
    "#         title = entry.get('title', '').replace('{', '').replace('}', '').replace('\\n', ' ').strip()\n",
    "#         abstract = entry.get('abstract', '').replace('{', '').replace('}', '').replace('\\n', ' ').strip()\n",
    "        \n",
    "#         # Combine the title and abstract directly without normalization\n",
    "#         text_feature = f\"{title} {abstract}\".strip()\n",
    "        \n",
    "#         # Append the raw combined text to the list\n",
    "#         entries_list.append(text_feature)\n",
    "\n",
    "#     return entries_list\n",
    "\n",
    "\n",
    "def parse_bib_file_to_dict(file_path):\n",
    "    \"\"\"Parse a BibTeX file and return a list of dictionaries with combined title and abstract and full entry data.\"\"\"\n",
    "    with open(file_path, encoding='utf-8') as bibtex_file:\n",
    "        parser = BibTexParser(common_strings=True)\n",
    "        bib_database = bibtexparser.load(bibtex_file, parser=parser)\n",
    "\n",
    "    entries_list = []\n",
    "    for entry in bib_database.entries:\n",
    "        title = entry.get('title', '').replace('{', '').replace('}', '').replace('\\n', ' ').strip()\n",
    "        abstract = entry.get('abstract', '').replace('{', '').replace('}', '').replace('\\n', ' ').strip()\n",
    "        text_feature = f\"{title} {abstract}\".strip()\n",
    "        entry_dict = {\n",
    "            'combined_text': text_feature,\n",
    "            'full_entry': entry  # Store the whole entry for later use\n",
    "        }\n",
    "        entries_list.append(entry_dict)\n",
    "\n",
    "    return entries_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8e1fc9e-a2ae-4d2a-9e92-cecbcfb208b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_bib_file_dir = \"data/Papers_after_duplicates.bib\"\n",
    "extracted_texts = [entry['combined_text'] for entry in parse_bib_file_to_dict(original_bib_file_dir)]\n",
    "processed_extracted_texts = normalize_and_process_text(extracted_texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "38010853-39da-4bae-9cad-5a6e15643050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(predicted_texts, processed_extracted_texts, full_entries):\n",
    "    matched_entries = []\n",
    "    unmatched_texts = []\n",
    "\n",
    "    for pred_text in predicted_texts:\n",
    "        if pred_text in processed_extracted_texts:\n",
    "            index = processed_extracted_texts.index(pred_text)\n",
    "            matched_entries.append(full_entries[index]['full_entry'])\n",
    "        else:\n",
    "            unmatched_texts.append(pred_text)\n",
    "\n",
    "    return matched_entries, unmatched_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "64b6c28e-47ee-4a77-9f45-9e8fb6b39ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_titles_and_abstracts = relevant_df['Title_and_Abstract'].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7d5e5c8a-8063-41bc-a73a-d7fe80c86adc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_texts_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m full_entries \u001b[38;5;241m=\u001b[39m parse_bib_file_to_dict(original_bib_file_dir)\n\u001b[1;32m      2\u001b[0m processed_full_texts \u001b[38;5;241m=\u001b[39m normalize_and_process_text([entry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m full_entries], tokenizer)\n\u001b[0;32m----> 5\u001b[0m matched_full_entries, unmatched_predicted_texts \u001b[38;5;241m=\u001b[39m find_matches(\u001b[43mpredicted_texts_processed\u001b[49m, processed_full_texts, full_entries)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted_texts_processed' is not defined"
     ]
    }
   ],
   "source": [
    "full_entries = parse_bib_file_to_dict(original_bib_file_dir)\n",
    "processed_full_texts = normalize_and_process_text([entry['combined_text'] for entry in full_entries], tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "efe90cdd-7d9b-4912-bd3a-f2b2678462b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_full_entries, unmatched_predicted_texts = find_matches(predicted_titles_and_abstracts, processed_full_texts, full_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9805aab-c750-4946-bfd4-906614a89775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2261"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matched_full_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d5fcb8d7-0005-4ac9-84e5-6983d9b551b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'annote': 'Query date: 2024-03-27 10:39:16',\n",
       "  'note': 'Publisher: papers.ssrn.com',\n",
       "  'author': 'Kum, S. W. and Moon, J. and Oh, S. and Suh, H. K. and Park, H. and {...}',\n",
       "  'journal': 'Available at SSRN …',\n",
       "  'abstract': '… With the advent of deep learning technology, recent studies are focusing on crop … agriculture is keep increasing, from conventional image processing to cutting-edge deep learning …',\n",
       "  'url': 'https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4583976',\n",
       "  'title': 'Novel {Method} for {Crop} {Growth} {Tracking} with {Deep} {Learning} {Model} on an {Edge} {Rail} {Camera}',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'kum_novel_nodate'},\n",
       " {'annote': 'Cited by: 0; All Open Access, Gold Open Access, Green Open Access',\n",
       "  'note': 'Publisher: mdpi.com\\nType: HTML',\n",
       "  'year': '2023',\n",
       "  'author': 'Blanco-Carmona, P. and Baeza-Moreno, L. and Hidalgo-Fort, E. and {...}',\n",
       "  'journal': 'Sensors',\n",
       "  'abstract': '… machine learning algorithm (Figure 4): Once a month, the server uses the collected environmental data to retrain each machine learning … This work permits the use of edge computing …',\n",
       "  'url': 'https://www.mdpi.com/1424-8220/23/24/9733',\n",
       "  'title': '{AIoT} in {Agriculture}: {Safeguarding} {Crops} from {Pest} and {Disease} {Threats}',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'blanco-carmona_aiot_2023'},\n",
       " {'annote': '1 cites: https://scholar.google.com/scholar?cites=11096721107342697011\\\\&as\\\\_sdt=2005\\\\&sciodt=2007\\\\&hl=en',\n",
       "  'year': '2023',\n",
       "  'author': 'Gravemeier, L. S. and Dittmer, A. and Jakob, M. and Kümper, D. and {...}',\n",
       "  'publisher': 'dl.gi.de',\n",
       "  'abstract': '… Machine-Learning-based pre-processing will be passed over to a data broker handling all information flows of the edge AI … support for artificial intelligence (AI) in agriculture as funding …',\n",
       "  'url': 'https://dl.gi.de/items/030b657a-4ace-4148-a54b-648027ae9f27',\n",
       "  'title': 'Conceptualizing a holistic smart dairy farming system',\n",
       "  'ENTRYTYPE': 'book',\n",
       "  'ID': 'gravemeier_conceptualizing_2023'},\n",
       " {'annote': 'Query date: 2024-03-27 10:39:16',\n",
       "  'keywords': 'Deep learning, Computer vision, Plant disease detection, Plant diseases, Crop monitoring, Safety, Sensor fusion, Image sensors, Sensor systems, Data models, Cameras',\n",
       "  'note': 'Publisher: ieeexplore.ieee.org',\n",
       "  'year': '2023',\n",
       "  'author': 'Wu, J. and Dar, U. and Anisi, M. H. and Abolghasemi, V. and {...}',\n",
       "  'booktitle': '… {IEEE} {Conference} on …',\n",
       "  'abstract': '… of diseases in agriculture. With the continuous development of deep learning from one hand, … A smart crop growth monitoring using edge artificial intelligence (AI) was developed in [7] …',\n",
       "  'url': 'https://ieeexplore.ieee.org/abstract/document/10291622/',\n",
       "  'title': 'Plant {Disease} {Detection}: {Electronic} {System} {Design} {Empowered} with {Artificial} {Intelligence}',\n",
       "  'ENTRYTYPE': 'inproceedings',\n",
       "  'ID': 'wu_plant_2023'},\n",
       " {'annote': '15 cites: https://scholar.google.com/scholar?cites=1352855713729473879\\\\&as\\\\_sdt=2005\\\\&sciodt=2007\\\\&hl=en',\n",
       "  'note': 'Publisher: mdpi.com\\nType: HTML',\n",
       "  'year': '2023',\n",
       "  'author': 'Ojo, M. O. and Zahid, A.',\n",
       "  'journal': 'Agronomy',\n",
       "  'abstract': '… (CEA) has progressively come to represent the growth of modern agriculture … edge computing devices in our future work to achieve real-time plant disease diagnosis using edge-AI …',\n",
       "  'url': 'https://www.mdpi.com/2073-4395/13/3/887',\n",
       "  'title': 'Improving deep learning classifiers performance via preprocessing and class imbalance approaches in a plant disease detection pipeline',\n",
       "  'ENTRYTYPE': 'article',\n",
       "  'ID': 'ojo_improving_2023'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_full_entries[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa1edd59-9370-4799-8824-45c9111a03d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_to_bibtex(entry):\n",
    "    \"\"\"Convert a dictionary entry to a BibTeX-formatted string.\"\"\"\n",
    "    bibtex_entry = f\"@{entry['ENTRYTYPE']}{{{entry['ID']},\\n\"\n",
    "    for key, value in entry.items():\n",
    "        if key not in ['ENTRYTYPE', 'ID']:  # Skip type and ID as they are already used\n",
    "            bibtex_entry += f\"  {key} = {{{value}}},\\n\"\n",
    "    bibtex_entry += \"}\\n\"\n",
    "    return bibtex_entry\n",
    "\n",
    "\n",
    "def save_matched_entries_to_bib(matched_entries, filename):\n",
    "    \"\"\"Save matched entries to a BibTeX file.\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        for entry in matched_entries:\n",
    "            bibtex_string = entry_to_bibtex(entry)\n",
    "            file.write(bibtex_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be614d42-b5b1-4363-9681-f12344c7c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_matched_entries_to_bib(matched_full_entries, 'matched_entries.bib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d465bc6-c187-49ae-a116-bc35b36913a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4491baf-b957-4386-862a-6b48e296fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_and_process_text(texts, tokenizer):\n",
    "#     \"\"\"Normalize and process texts using a tokenizer and decode them back to strings.\"\"\"\n",
    "#     tokenized_texts = tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "#     decoded_texts = [tokenizer.decode(t, skip_special_tokens=True) for t in tokenized_texts.input_ids]\n",
    "#     return decoded_texts\n",
    "\n",
    "\n",
    "# def match_entries(predicted_list, bib_entries_list):\n",
    "#     \"\"\"Match predicted titles and abstracts against BibTeX entries and categorize into matched and unmatched.\"\"\"\n",
    "#     matched = []\n",
    "#     unmatched = []\n",
    "\n",
    "#     # Convert bib_entries_list to a set for faster lookup\n",
    "#     bib_entries_set = set(bib_entries_list)\n",
    "\n",
    "#     for predicted in predicted_list:\n",
    "#         if predicted in bib_entries_set:\n",
    "#             matched.append(predicted)\n",
    "#         else:\n",
    "#             unmatched.append(predicted)\n",
    "\n",
    "#     return matched, unmatched\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b0ad3884-57bc-4c82-9efb-069614f399bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input texts should be a list of strings.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m processed_extracted_texts \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_and_process_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitles_and_abstracts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 10\u001b[0m, in \u001b[0;36mnormalize_and_process_text\u001b[0;34m(texts, tokenizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Normalize and process texts using a tokenizer and decode them back to strings.\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(texts, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(t, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m texts):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput texts should be a list of strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m tokenized_texts \u001b[38;5;241m=\u001b[39m tokenizer(texts, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m decoded_texts \u001b[38;5;241m=\u001b[39m [tokenizer\u001b[38;5;241m.\u001b[39mdecode(t, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokenized_texts\u001b[38;5;241m.\u001b[39minput_ids]\n",
      "\u001b[0;31mValueError\u001b[0m: Input texts should be a list of strings."
     ]
    }
   ],
   "source": [
    "processed_extracted_texts = normalize_and_process_text(titles_and_abstracts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a43bf198-4088-45c2-ac54-023b345db462",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_entries, unmatched_entries = match_entries(predicted_titles_and_abstracts,processed_extracted_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77bc0a9d-cad7-42e0-b6a3-577b7a1002d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2261"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matched_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16ad9be3-a0d0-4930-b1e0-566d583260f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatched_entries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
